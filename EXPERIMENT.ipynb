{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "import multiprocessing\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import optimizeTopicVectors as ot\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hoseong's class\n",
    "from STMD import *\n",
    "from ASUM import *\n",
    "from ASUM_Embedding import *\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "# work_path = \"/media/hs-ubuntu/data/dataset/MasterThesis/STMD_data/\"\n",
    "work_path = \"E:/dataset/MasterThesis/STMD_data/\"\n",
    "\n",
    "data = pd.read_csv(work_path + \"preprocess_complete_Electronics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_sample(data, brand_name, count, ratio = 1, random_state = 42):\n",
    "    brand = data[data['brand']==brand_name]\n",
    "    pos_reviews = brand[brand.overall >= 4]\n",
    "    neg_reviews = brand[brand.overall <= 2]\n",
    "    if ratio == 1:\n",
    "        pos_sample = pos_reviews.sample(count, random_state=random_state)\n",
    "        neg_sample = neg_reviews.sample(count, random_state=random_state)\n",
    "        df = pd.concat([pos_sample, neg_sample], axis=0)\n",
    "    else:\n",
    "        df = brand.sample(count * 2, random_state = random_state)\n",
    "    df['preprocessed'] = df.preprocessed.apply(lambda row: literal_eval(row))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# brand = ['Apple', 'Samsung','Canon']\n",
    "# brand_df = data[data.brand.isin(brand)]\n",
    "# brand_df.reset_index(drop=True, inplace=True)\n",
    "# #긍정, 부정 반반씩\n",
    "# pos_reviews = brand_df[brand_df.overall >= 4]\n",
    "# neg_reviews = brand_df[brand_df.overall <= 2]\n",
    "# pos_sample = pos_reviews.sample(3500, random_state=23)\n",
    "# neg_sample = neg_reviews.sample(3500, random_state=42)\n",
    "# df = pd.concat([pos_sample, neg_sample], axis=0)\n",
    "# df['preprocessed'] = df.preprocessed.apply(lambda row: literal_eval(row))\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# apple, samsung, canon 1:1:1\n",
    "apple = extract_sample(data, 'Apple', 500, ratio = 1)\n",
    "samsung = extract_sample(data, 'Samsung', 500, ratio = 1)\n",
    "canon = extract_sample(data, 'Canon', 500, ratio = 1)\n",
    "df = pd.concat([apple, samsung, canon], axis=0)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 12)\n",
      "(1500, 12)\n"
     ]
    }
   ],
   "source": [
    "print(df[df.overall >= 4].shape)\n",
    "print(df[df.overall <= 2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare\n",
    "sentence_list, sentiment_label, sentence_senti_label, \\\n",
    "pos_neg_sentence_indices, pos_neg_sentiment_label, numSentence = prepare(df)\n",
    "\n",
    "documents, sentence_list_again, bigram, documents_label\\\n",
    "= bigram_and_sentence(sentence_senti_label, sentence_list, numSentence, max_vocab=5000, threshold = 5, min_count = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27123"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gensim_model(documents, window, dimension, epochs, save_path, save_per_epoch = 5, save=True):\n",
    "    model = Doc2Vec(dm=1, dm_mean=1, negative =10,min_count=0, sample=1e-5,\n",
    "                    window=window, size=dimension, \n",
    "                    workers=multiprocessing.cpu_count(), \n",
    "                    alpha=0.025, min_alpha=0.025)\n",
    "    model.build_vocab(documents)\n",
    "    decrease_rate = 0.025 / epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        random.shuffle(documents)\n",
    "        model.train(documents)\n",
    "        model.alpha -= decrease_rate  # decrease the learning rate\n",
    "        model.min_alpha = model.alpha  # fix the learning rate, no decay\n",
    "        if (epoch + 1) % save_per_epoch ==0:\n",
    "            if save:\n",
    "                model.save(save_path + 'model_' + str(window) + '_' + str(dimension) + '_' + str(epoch+1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:49<00:00, 11.39s/it]\n"
     ]
    }
   ],
   "source": [
    "# word / sentiment embedding\n",
    "\n",
    "window = [3]\n",
    "size = [100]\n",
    "passes = 10\n",
    "for w in window:\n",
    "    for s in size:\n",
    "        model = Doc2Vec(dm=1, dm_mean=1, negative =10,min_count=0, sample=1e-5,\n",
    "                        window=w, size=s, \n",
    "                        workers=multiprocessing.cpu_count(), \n",
    "                        alpha=0.025, min_alpha=0.025)\n",
    "        model.build_vocab(documents)\n",
    "\n",
    "        for epoch in tqdm(range(passes)):\n",
    "            random.shuffle(documents)\n",
    "            model.train(documents)\n",
    "            model.alpha -= 0.002  # decrease the learning rate\n",
    "            model.min_alpha = model.alpha  # fix the learning rate, no decay\n",
    "#             if (epoch + 1) % 5 ==0:\n",
    "#                 model.save(model_path + 'model_' + str(w) + '_' + str(s) + '_' + str(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "unknown URI scheme 'e' in 'E:/dataset/MasterThesis/gensim_models/test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-131bea14d101>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"E:/dataset/MasterThesis/gensim_models/test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/hs-ubuntu/anaconda3/lib/python3.5/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1486\u001b[0m         \u001b[0;31m# update older models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'table'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hs-ubuntu/anaconda3/lib/python3.5/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hs-ubuntu/anaconda3/lib/python3.5/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;34m\"\"\"Load pickled object from `fname`\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m         \u001b[0;31m# Because of loading from S3 load can't be used (missing readline in smart_open)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hs-ubuntu/anaconda3/lib/python3.5/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# this method just routes the request to classes handling the specific storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# schemes, depending on the URI protocol in `uri`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mparsed_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParseUri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"file\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hs-ubuntu/anaconda3/lib/python3.5/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, default_scheme)\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid file URI: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown URI scheme %r in %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: unknown URI scheme 'e' in 'E:/dataset/MasterThesis/gensim_models/test'"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec.load(\"E:/dataset/MasterThesis/gensim_models/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"E:/dataset/MasterThesis/gensim_models/test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordVectors = np.zeros((len(model.index2word), model.vector_size))\n",
    "for index, word in enumerate(model.index2word):\n",
    "    wordVectors[index,:] = model[word]\n",
    "\n",
    "sentimentVector = np.zeros((2, model.vector_size))\n",
    "sentimentVector[0,:] = model.docvecs['positive']\n",
    "sentimentVector[1,:] = model.docvecs['negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ratio is  0.0\n",
      "Starting iteration 10 of 100\n",
      "0.672\n",
      "Starting iteration 20 of 100\n",
      "0.601333333333\n",
      "Starting iteration 30 of 100\n",
      "0.6\n",
      "Starting iteration 40 of 100\n",
      "0.611666666667\n",
      "Starting iteration 50 of 100\n",
      "0.603666666667\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.607\n",
      "Starting iteration 70 of 100\n",
      "0.610333333333\n",
      "Starting iteration 80 of 100\n",
      "0.612666666667\n",
      "Starting iteration 90 of 100\n",
      "0.614\n",
      "Starting iteration 100 of 100\n",
      "0.62\n",
      "Starting save model\n",
      "-----ratio is  0.1\n",
      "Starting iteration 10 of 100\n",
      "0.709666666667\n",
      "Starting iteration 20 of 100\n",
      "0.719\n",
      "Starting iteration 30 of 100\n",
      "0.734333333333\n",
      "Starting iteration 40 of 100\n",
      "0.735\n",
      "Starting iteration 50 of 100\n",
      "0.743666666667\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.742666666667\n",
      "Starting iteration 70 of 100\n",
      "0.746\n",
      "Starting iteration 80 of 100\n",
      "0.735666666667\n",
      "Starting iteration 90 of 100\n",
      "0.738333333333\n",
      "Starting iteration 100 of 100\n",
      "0.732\n",
      "Starting save model\n",
      "-----ratio is  0.2\n",
      "Starting iteration 10 of 100\n",
      "0.731\n",
      "Starting iteration 20 of 100\n",
      "0.738333333333\n",
      "Starting iteration 30 of 100\n",
      "0.734333333333\n",
      "Starting iteration 40 of 100\n",
      "0.737\n",
      "Starting iteration 50 of 100\n",
      "0.746\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.730666666667\n",
      "Starting iteration 70 of 100\n",
      "0.731333333333\n",
      "Starting iteration 80 of 100\n",
      "0.735666666667\n",
      "Starting iteration 90 of 100\n",
      "0.727\n",
      "Starting iteration 100 of 100\n",
      "0.736666666667\n",
      "Starting save model\n",
      "-----ratio is  0.3\n",
      "Starting iteration 10 of 100\n",
      "0.737666666667\n",
      "Starting iteration 20 of 100\n",
      "0.745\n",
      "Starting iteration 30 of 100\n",
      "0.734333333333\n",
      "Starting iteration 40 of 100\n",
      "0.729333333333\n",
      "Starting iteration 50 of 100\n",
      "0.741666666667\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.734333333333\n",
      "Starting iteration 70 of 100\n",
      "0.735333333333\n",
      "Starting iteration 80 of 100\n",
      "0.739\n",
      "Starting iteration 90 of 100\n",
      "0.738\n",
      "Starting iteration 100 of 100\n",
      "0.743333333333\n",
      "Starting save model\n",
      "-----ratio is  0.4\n",
      "Starting iteration 10 of 100\n",
      "0.735\n",
      "Starting iteration 20 of 100\n",
      "0.735333333333\n",
      "Starting iteration 30 of 100\n",
      "0.741333333333\n",
      "Starting iteration 40 of 100\n",
      "0.74\n",
      "Starting iteration 50 of 100\n",
      "0.744\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.740666666667\n",
      "Starting iteration 70 of 100\n",
      "0.741\n",
      "Starting iteration 80 of 100\n",
      "0.752333333333\n",
      "Starting iteration 90 of 100\n",
      "0.738666666667\n",
      "Starting iteration 100 of 100\n",
      "0.733333333333\n",
      "Starting save model\n",
      "-----ratio is  0.5\n",
      "Starting iteration 10 of 100\n",
      "0.738333333333\n",
      "Starting iteration 20 of 100\n",
      "0.743666666667\n",
      "Starting iteration 30 of 100\n",
      "0.747\n",
      "Starting iteration 40 of 100\n",
      "0.736666666667\n",
      "Starting iteration 50 of 100\n",
      "0.744\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.739333333333\n",
      "Starting iteration 70 of 100\n",
      "0.737\n",
      "Starting iteration 80 of 100\n",
      "0.737\n",
      "Starting iteration 90 of 100\n",
      "0.743\n",
      "Starting iteration 100 of 100\n",
      "0.731666666667\n",
      "Starting save model\n",
      "-----ratio is  0.6\n",
      "Starting iteration 10 of 100\n",
      "0.736\n",
      "Starting iteration 20 of 100\n",
      "0.751333333333\n",
      "Starting iteration 30 of 100\n",
      "0.74\n",
      "Starting iteration 40 of 100\n",
      "0.745666666667\n",
      "Starting iteration 50 of 100\n",
      "0.740333333333\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.740666666667\n",
      "Starting iteration 70 of 100\n",
      "0.744333333333\n",
      "Starting iteration 80 of 100\n",
      "0.736333333333\n",
      "Starting iteration 90 of 100\n",
      "0.736333333333\n",
      "Starting iteration 100 of 100\n",
      "0.738666666667\n",
      "Starting save model\n",
      "-----ratio is  0.7\n",
      "Starting iteration 10 of 100\n",
      "0.739\n",
      "Starting iteration 20 of 100\n",
      "0.744\n",
      "Starting iteration 30 of 100\n",
      "0.740666666667\n",
      "Starting iteration 40 of 100\n",
      "0.739333333333\n",
      "Starting iteration 50 of 100\n",
      "0.740333333333\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.738333333333\n",
      "Starting iteration 70 of 100\n",
      "0.734\n",
      "Starting iteration 80 of 100\n",
      "0.737666666667\n",
      "Starting iteration 90 of 100\n",
      "0.748333333333\n",
      "Starting iteration 100 of 100\n",
      "0.738666666667\n",
      "Starting save model\n",
      "-----ratio is  0.8\n",
      "Starting iteration 10 of 100\n",
      "0.74\n",
      "Starting iteration 20 of 100\n",
      "0.742666666667\n",
      "Starting iteration 30 of 100\n",
      "0.741666666667\n",
      "Starting iteration 40 of 100\n",
      "0.739\n",
      "Starting iteration 50 of 100\n",
      "0.741\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.738333333333\n",
      "Starting iteration 70 of 100\n",
      "0.746666666667\n",
      "Starting iteration 80 of 100\n",
      "0.739\n",
      "Starting iteration 90 of 100\n",
      "0.746666666667\n",
      "Starting iteration 100 of 100\n",
      "0.741333333333\n",
      "Starting save model\n",
      "-----ratio is  0.9\n",
      "Starting iteration 10 of 100\n",
      "0.736333333333\n",
      "Starting iteration 20 of 100\n",
      "0.737666666667\n",
      "Starting iteration 30 of 100\n",
      "0.737\n",
      "Starting iteration 40 of 100\n",
      "0.74\n",
      "Starting iteration 50 of 100\n",
      "0.737666666667\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.742333333333\n",
      "Starting iteration 70 of 100\n",
      "0.744333333333\n",
      "Starting iteration 80 of 100\n",
      "0.736\n",
      "Starting iteration 90 of 100\n",
      "0.737666666667\n",
      "Starting iteration 100 of 100\n",
      "0.741333333333\n",
      "Starting save model\n",
      "-----ratio is  1.0\n",
      "Starting iteration 10 of 100\n",
      "0.741666666667\n",
      "Starting iteration 20 of 100\n",
      "0.743333333333\n",
      "Starting iteration 30 of 100\n",
      "0.738333333333\n",
      "Starting iteration 40 of 100\n",
      "0.742333333333\n",
      "Starting iteration 50 of 100\n",
      "0.737666666667\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.736\n",
      "Starting iteration 70 of 100\n",
      "0.736\n",
      "Starting iteration 80 of 100\n",
      "0.738333333333\n",
      "Starting iteration 90 of 100\n",
      "0.740333333333\n",
      "Starting iteration 100 of 100\n",
      "0.743333333333\n",
      "Starting save model\n",
      "Wall time: 3h 16min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ratios = np.linspace(0,1,11)\n",
    "for ratio in ratios:\n",
    "    print(\"-----ratio is \", ratio)\n",
    "    asum_embedding_path = \"E:/dataset/MasterThesis/Models/ASUM_embedding\" + str(ratio)\n",
    "    asum_embedding = ASUM_Embedding(wordVectors, sentimentVector, numTopics=10, alpha=0.01, beta=0.001, gamma=1, binary=ratio, numSentiments=2)\n",
    "    asum_embedding._initialize_(sentence_list_again, pos_neg_sentence_indices, pos_neg_sentiment_label, sentiment_label)\n",
    "    asum_embedding.run(sentence_list_again, save_path=asum_embedding_path, print_iter=10, save_iter = 50, maxIters= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:42<00:00,  8.64s/it]\n"
     ]
    }
   ],
   "source": [
    "# word / sentiment embedding\n",
    "\n",
    "window = [3]\n",
    "size = [100]\n",
    "passes = 5\n",
    "for w in window:\n",
    "    for s in size:\n",
    "        model = Doc2Vec(dm=1, dm_mean=1, negative =10,min_count=0, sample=1e-5,\n",
    "                        window=w, size=s, \n",
    "                        workers=multiprocessing.cpu_count(), \n",
    "                        alpha=0.025, min_alpha=0.025)\n",
    "        model.build_vocab(documents)\n",
    "\n",
    "        for epoch in tqdm(range(passes)):\n",
    "            random.shuffle(documents)\n",
    "            model.train(documents)\n",
    "            model.alpha -= 0.002  # decrease the learning rate\n",
    "            model.min_alpha = model.alpha  # fix the learning rate, no decay\n",
    "#             if (epoch + 1) % 5 ==0:\n",
    "#                 model.save(model_path + 'model_' + str(w) + '_' + str(s) + '_' + str(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ratio is  0.0\n",
      "Starting iteration 10 of 100\n",
      "0.671666666667\n",
      "Starting iteration 20 of 100\n",
      "0.676\n",
      "Starting iteration 30 of 100\n",
      "0.676666666667\n",
      "Starting iteration 40 of 100\n",
      "0.687666666667\n",
      "Starting iteration 50 of 100\n",
      "0.694\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.701666666667\n",
      "Starting iteration 70 of 100\n",
      "0.703\n",
      "Starting iteration 80 of 100\n",
      "0.699666666667\n",
      "Starting iteration 90 of 100\n",
      "0.705\n",
      "Starting iteration 100 of 100\n",
      "0.709333333333\n",
      "Starting save model\n",
      "-----ratio is  0.1\n",
      "Starting iteration 10 of 100\n",
      "0.68\n",
      "Starting iteration 20 of 100\n",
      "0.673\n",
      "Starting iteration 30 of 100\n",
      "0.691333333333\n",
      "Starting iteration 40 of 100\n",
      "0.687333333333\n",
      "Starting iteration 50 of 100\n",
      "0.692666666667\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.693666666667\n",
      "Starting iteration 70 of 100\n",
      "0.699333333333\n",
      "Starting iteration 80 of 100\n",
      "0.708\n",
      "Starting iteration 90 of 100\n",
      "0.706666666667\n",
      "Starting iteration 100 of 100\n",
      "0.717333333333\n",
      "Starting save model\n",
      "-----ratio is  0.2\n",
      "Starting iteration 10 of 100\n",
      "0.697333333333\n",
      "Starting iteration 20 of 100\n",
      "0.707\n",
      "Starting iteration 30 of 100\n",
      "0.716\n",
      "Starting iteration 40 of 100\n",
      "0.720666666667\n",
      "Starting iteration 50 of 100\n",
      "0.727333333333\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.718333333333\n",
      "Starting iteration 70 of 100\n",
      "0.715333333333\n",
      "Starting iteration 80 of 100\n",
      "0.716\n",
      "Starting iteration 90 of 100\n",
      "0.717\n",
      "Starting iteration 100 of 100\n",
      "0.714666666667\n",
      "Starting save model\n",
      "-----ratio is  0.3\n",
      "Starting iteration 10 of 100\n",
      "0.700333333333\n",
      "Starting iteration 20 of 100\n",
      "0.713\n",
      "Starting iteration 30 of 100\n",
      "0.711\n",
      "Starting iteration 40 of 100\n",
      "0.703\n",
      "Starting iteration 50 of 100\n",
      "0.716666666667\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.707666666667\n",
      "Starting iteration 70 of 100\n",
      "0.719666666667\n",
      "Starting iteration 80 of 100\n",
      "0.719333333333\n",
      "Starting iteration 90 of 100\n",
      "0.709666666667\n",
      "Starting iteration 100 of 100\n",
      "0.709666666667\n",
      "Starting save model\n",
      "-----ratio is  0.4\n",
      "Starting iteration 10 of 100\n",
      "0.704\n",
      "Starting iteration 20 of 100\n",
      "0.696333333333\n",
      "Starting iteration 30 of 100\n",
      "0.715333333333\n",
      "Starting iteration 40 of 100\n",
      "0.716666666667\n",
      "Starting iteration 50 of 100\n",
      "0.709\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.715\n",
      "Starting iteration 70 of 100\n",
      "0.723666666667\n",
      "Starting iteration 80 of 100\n",
      "0.721333333333\n",
      "Starting iteration 90 of 100\n",
      "0.713333333333\n",
      "Starting iteration 100 of 100\n",
      "0.72\n",
      "Starting save model\n",
      "-----ratio is  0.5\n",
      "Starting iteration 10 of 100\n",
      "0.705\n",
      "Starting iteration 20 of 100\n",
      "0.706666666667\n",
      "Starting iteration 30 of 100\n",
      "0.697333333333\n",
      "Starting iteration 40 of 100\n",
      "0.712666666667\n",
      "Starting iteration 50 of 100\n",
      "0.708666666667\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.714666666667\n",
      "Starting iteration 70 of 100\n",
      "0.715666666667\n",
      "Starting iteration 80 of 100\n",
      "0.713\n",
      "Starting iteration 90 of 100\n",
      "0.710666666667\n",
      "Starting iteration 100 of 100\n",
      "0.713333333333\n",
      "Starting save model\n",
      "-----ratio is  0.6\n",
      "Starting iteration 10 of 100\n",
      "0.707666666667\n",
      "Starting iteration 20 of 100\n",
      "0.698666666667\n",
      "Starting iteration 30 of 100\n",
      "0.704333333333\n",
      "Starting iteration 40 of 100\n",
      "0.706666666667\n",
      "Starting iteration 50 of 100\n",
      "0.704666666667\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.706\n",
      "Starting iteration 70 of 100\n",
      "0.707\n",
      "Starting iteration 80 of 100\n",
      "0.705333333333\n",
      "Starting iteration 90 of 100\n",
      "0.704333333333\n",
      "Starting iteration 100 of 100\n",
      "0.718666666667\n",
      "Starting save model\n",
      "-----ratio is  0.7\n",
      "Starting iteration 10 of 100\n",
      "0.705\n",
      "Starting iteration 20 of 100\n",
      "0.704\n",
      "Starting iteration 30 of 100\n",
      "0.706333333333\n",
      "Starting iteration 40 of 100\n",
      "0.703\n",
      "Starting iteration 50 of 100\n",
      "0.698333333333\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.705666666667\n",
      "Starting iteration 70 of 100\n",
      "0.705333333333\n",
      "Starting iteration 80 of 100\n",
      "0.711\n",
      "Starting iteration 90 of 100\n",
      "0.702\n",
      "Starting iteration 100 of 100\n",
      "0.7\n",
      "Starting save model\n",
      "-----ratio is  0.8\n",
      "Starting iteration 10 of 100\n",
      "0.693333333333\n",
      "Starting iteration 20 of 100\n",
      "0.704333333333\n",
      "Starting iteration 30 of 100\n",
      "0.704666666667\n",
      "Starting iteration 40 of 100\n",
      "0.702666666667\n",
      "Starting iteration 50 of 100\n",
      "0.7\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.69\n",
      "Starting iteration 70 of 100\n",
      "0.713\n",
      "Starting iteration 80 of 100\n",
      "0.699333333333\n",
      "Starting iteration 90 of 100\n",
      "0.702333333333\n",
      "Starting iteration 100 of 100\n",
      "0.695333333333\n",
      "Starting save model\n",
      "-----ratio is  0.9\n",
      "Starting iteration 10 of 100\n",
      "0.699666666667\n",
      "Starting iteration 20 of 100\n",
      "0.697666666667\n",
      "Starting iteration 30 of 100\n",
      "0.704\n",
      "Starting iteration 40 of 100\n",
      "0.697333333333\n",
      "Starting iteration 50 of 100\n",
      "0.695666666667\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.702\n",
      "Starting iteration 70 of 100\n",
      "0.699\n",
      "Starting iteration 80 of 100\n",
      "0.695\n",
      "Starting iteration 90 of 100\n",
      "0.695333333333\n",
      "Starting iteration 100 of 100\n",
      "0.696\n",
      "Starting save model\n",
      "-----ratio is  1.0\n",
      "Starting iteration 10 of 100\n",
      "0.697333333333\n",
      "Starting iteration 20 of 100\n",
      "0.698333333333\n",
      "Starting iteration 30 of 100\n",
      "0.693\n",
      "Starting iteration 40 of 100\n",
      "0.695\n",
      "Starting iteration 50 of 100\n",
      "0.697333333333\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.695\n",
      "Starting iteration 70 of 100\n",
      "0.697\n",
      "Starting iteration 80 of 100\n",
      "0.695666666667\n",
      "Starting iteration 90 of 100\n",
      "0.690333333333\n",
      "Starting iteration 100 of 100\n",
      "0.696333333333\n",
      "Starting save model\n",
      "Wall time: 3h 16min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.save(\"E:/dataset/MasterThesis/gensim_models/test2\")\n",
    "wordVectors = np.zeros((len(model.index2word), model.vector_size))\n",
    "for index, word in enumerate(model.index2word):\n",
    "    wordVectors[index,:] = model[word]\n",
    "\n",
    "sentimentVector = np.zeros((2, model.vector_size))\n",
    "sentimentVector[0,:] = model.docvecs['positive']\n",
    "sentimentVector[1,:] = model.docvecs['negative']\n",
    "\n",
    "\n",
    "ratios = np.linspace(0,1,11)\n",
    "for ratio in ratios:\n",
    "    print(\"-----ratio is \", ratio)\n",
    "    asum_embedding_path = \"E:/dataset/MasterThesis/Models/ASUM_embedding\" + str(ratio)\n",
    "    asum_embedding = ASUM_Embedding(wordVectors, sentimentVector, numTopics=10, alpha=0.01, beta=0.001, gamma=1, binary=ratio, numSentiments=2)\n",
    "    asum_embedding._initialize_(sentence_list_again, pos_neg_sentence_indices, pos_neg_sentiment_label, sentiment_label)\n",
    "    asum_embedding.run(sentence_list_again, save_path=asum_embedding_path, print_iter=10, save_iter = 50, maxIters= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:28<00:00,  8.95s/it]\n"
     ]
    }
   ],
   "source": [
    "# word / sentiment embedding\n",
    "\n",
    "window = [5]\n",
    "size = [100]\n",
    "passes = 10\n",
    "for w in window:\n",
    "    for s in size:\n",
    "        model = Doc2Vec(dm=1, dm_mean=1, negative =10,min_count=0, sample=1e-5,\n",
    "                        window=w, size=s, \n",
    "                        workers=multiprocessing.cpu_count(), \n",
    "                        alpha=0.025, min_alpha=0.025)\n",
    "        model.build_vocab(documents)\n",
    "\n",
    "        for epoch in tqdm(range(passes)):\n",
    "            random.shuffle(documents)\n",
    "            model.train(documents)\n",
    "            model.alpha -= 0.002  # decrease the learning rate\n",
    "            model.min_alpha = model.alpha  # fix the learning rate, no decay\n",
    "#             if (epoch + 1) % 5 ==0:\n",
    "#                 model.save(model_path + 'model_' + str(w) + '_' + str(s) + '_' + str(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----ratio is  0.0\n",
      "Starting iteration 10 of 100\n",
      "0.667\n",
      "Starting iteration 20 of 100\n",
      "0.649666666667\n",
      "Starting iteration 30 of 100\n",
      "0.636666666667\n",
      "Starting iteration 40 of 100\n",
      "0.632666666667\n",
      "Starting iteration 50 of 100\n",
      "0.641666666667\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.633\n",
      "Starting iteration 70 of 100\n",
      "0.639333333333\n",
      "Starting iteration 80 of 100\n",
      "0.627666666667\n",
      "Starting iteration 90 of 100\n",
      "0.640666666667\n",
      "Starting iteration 100 of 100\n",
      "0.635666666667\n",
      "Starting save model\n",
      "-----ratio is  0.1\n",
      "Starting iteration 10 of 100\n",
      "0.672\n",
      "Starting iteration 20 of 100\n",
      "0.686\n",
      "Starting iteration 30 of 100\n",
      "0.699333333333\n",
      "Starting iteration 40 of 100\n",
      "0.701333333333\n",
      "Starting iteration 50 of 100\n",
      "0.709666666667\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.696666666667\n",
      "Starting iteration 70 of 100\n",
      "0.708\n",
      "Starting iteration 80 of 100\n",
      "0.705\n",
      "Starting iteration 90 of 100\n",
      "0.697\n",
      "Starting iteration 100 of 100\n",
      "0.705333333333\n",
      "Starting save model\n",
      "-----ratio is  0.2\n",
      "Starting iteration 10 of 100\n",
      "0.689666666667\n",
      "Starting iteration 20 of 100\n",
      "0.709\n",
      "Starting iteration 30 of 100\n",
      "0.710333333333\n",
      "Starting iteration 40 of 100\n",
      "0.719666666667\n",
      "Starting iteration 50 of 100\n",
      "0.723\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.729\n",
      "Starting iteration 70 of 100\n",
      "0.722666666667\n",
      "Starting iteration 80 of 100\n",
      "0.716333333333\n",
      "Starting iteration 90 of 100\n",
      "0.723666666667\n",
      "Starting iteration 100 of 100\n",
      "0.723333333333\n",
      "Starting save model\n",
      "-----ratio is  0.3\n",
      "Starting iteration 10 of 100\n",
      "0.718666666667\n",
      "Starting iteration 20 of 100\n",
      "0.717\n",
      "Starting iteration 30 of 100\n",
      "0.723666666667\n",
      "Starting iteration 40 of 100\n",
      "0.730333333333\n",
      "Starting iteration 50 of 100\n",
      "0.731\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.723\n",
      "Starting iteration 70 of 100\n",
      "0.721666666667\n",
      "Starting iteration 80 of 100\n",
      "0.724666666667\n",
      "Starting iteration 90 of 100\n",
      "0.725\n",
      "Starting iteration 100 of 100\n",
      "0.728666666667\n",
      "Starting save model\n",
      "-----ratio is  0.4\n",
      "Starting iteration 10 of 100\n",
      "0.714333333333\n",
      "Starting iteration 20 of 100\n",
      "0.726333333333\n",
      "Starting iteration 30 of 100\n",
      "0.720333333333\n",
      "Starting iteration 40 of 100\n",
      "0.722\n",
      "Starting iteration 50 of 100\n",
      "0.721333333333\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.725666666667\n",
      "Starting iteration 70 of 100\n",
      "0.734\n",
      "Starting iteration 80 of 100\n",
      "0.720333333333\n",
      "Starting iteration 90 of 100\n",
      "0.717\n",
      "Starting iteration 100 of 100\n",
      "0.731\n",
      "Starting save model\n",
      "-----ratio is  0.5\n",
      "Starting iteration 10 of 100\n",
      "0.723\n",
      "Starting iteration 20 of 100\n",
      "0.722666666667\n",
      "Starting iteration 30 of 100\n",
      "0.725\n",
      "Starting iteration 40 of 100\n",
      "0.719333333333\n",
      "Starting iteration 50 of 100\n",
      "0.721\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.724666666667\n",
      "Starting iteration 70 of 100\n",
      "0.733333333333\n",
      "Starting iteration 80 of 100\n",
      "0.716666666667\n",
      "Starting iteration 90 of 100\n",
      "0.722\n",
      "Starting iteration 100 of 100\n",
      "0.724666666667\n",
      "Starting save model\n",
      "-----ratio is  0.6\n",
      "Starting iteration 10 of 100\n",
      "0.711666666667\n",
      "Starting iteration 20 of 100\n",
      "0.725666666667\n",
      "Starting iteration 30 of 100\n",
      "0.710333333333\n",
      "Starting iteration 40 of 100\n",
      "0.73\n",
      "Starting iteration 50 of 100\n",
      "0.714666666667\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.715666666667\n",
      "Starting iteration 70 of 100\n",
      "0.715\n",
      "Starting iteration 80 of 100\n",
      "0.72\n",
      "Starting iteration 90 of 100\n",
      "0.717666666667\n",
      "Starting iteration 100 of 100\n",
      "0.721\n",
      "Starting save model\n",
      "-----ratio is  0.7\n",
      "Starting iteration 10 of 100\n",
      "0.71\n",
      "Starting iteration 20 of 100\n",
      "0.716333333333\n",
      "Starting iteration 30 of 100\n",
      "0.719666666667\n",
      "Starting iteration 40 of 100\n",
      "0.722\n",
      "Starting iteration 50 of 100\n",
      "0.716333333333\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.721666666667\n",
      "Starting iteration 70 of 100\n",
      "0.718333333333\n",
      "Starting iteration 80 of 100\n",
      "0.723333333333\n",
      "Starting iteration 90 of 100\n",
      "0.720666666667\n",
      "Starting iteration 100 of 100\n",
      "0.716333333333\n",
      "Starting save model\n",
      "-----ratio is  0.8\n",
      "Starting iteration 10 of 100\n",
      "0.709666666667\n",
      "Starting iteration 20 of 100\n",
      "0.714333333333\n",
      "Starting iteration 30 of 100\n",
      "0.714333333333\n",
      "Starting iteration 40 of 100\n",
      "0.720333333333\n",
      "Starting iteration 50 of 100\n",
      "0.717333333333\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.720333333333\n",
      "Starting iteration 70 of 100\n",
      "0.708\n",
      "Starting iteration 80 of 100\n",
      "0.710666666667\n",
      "Starting iteration 90 of 100\n",
      "0.722666666667\n",
      "Starting iteration 100 of 100\n",
      "0.718666666667\n",
      "Starting save model\n",
      "-----ratio is  0.9\n",
      "Starting iteration 10 of 100\n",
      "0.714666666667\n",
      "Starting iteration 20 of 100\n",
      "0.716\n",
      "Starting iteration 30 of 100\n",
      "0.713\n",
      "Starting iteration 40 of 100\n",
      "0.711666666667\n",
      "Starting iteration 50 of 100\n",
      "0.713666666667\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.715666666667\n",
      "Starting iteration 70 of 100\n",
      "0.716\n",
      "Starting iteration 80 of 100\n",
      "0.715333333333\n",
      "Starting iteration 90 of 100\n",
      "0.714\n",
      "Starting iteration 100 of 100\n",
      "0.711\n",
      "Starting save model\n",
      "-----ratio is  1.0\n",
      "Starting iteration 10 of 100\n",
      "0.712666666667\n",
      "Starting iteration 20 of 100\n",
      "0.710666666667\n",
      "Starting iteration 30 of 100\n",
      "0.715666666667\n",
      "Starting iteration 40 of 100\n",
      "0.712666666667\n",
      "Starting iteration 50 of 100\n",
      "0.710666666667\n",
      "Starting save model\n",
      "Starting iteration 60 of 100\n",
      "0.712\n",
      "Starting iteration 70 of 100\n",
      "0.715666666667\n",
      "Starting iteration 80 of 100\n",
      "0.716333333333\n",
      "Starting iteration 90 of 100\n",
      "0.718666666667\n",
      "Starting iteration 100 of 100\n",
      "0.714\n",
      "Starting save model\n",
      "Wall time: 3h 18min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.save(\"E:/dataset/MasterThesis/gensim_models/test3\")\n",
    "wordVectors = np.zeros((len(model.index2word), model.vector_size))\n",
    "for index, word in enumerate(model.index2word):\n",
    "    wordVectors[index,:] = model[word]\n",
    "\n",
    "sentimentVector = np.zeros((2, model.vector_size))\n",
    "sentimentVector[0,:] = model.docvecs['positive']\n",
    "sentimentVector[1,:] = model.docvecs['negative']\n",
    "\n",
    "\n",
    "ratios = np.linspace(0,1,11)\n",
    "for ratio in ratios:\n",
    "    print(\"-----ratio is \", ratio)\n",
    "    asum_embedding_path = \"E:/dataset/MasterThesis/Models/ASUM_embedding\" + str(ratio)\n",
    "    asum_embedding = ASUM_Embedding(wordVectors, sentimentVector, numTopics=10, alpha=0.01, beta=0.001, gamma=1, binary=ratio, numSentiments=2)\n",
    "    asum_embedding._initialize_(sentence_list_again, pos_neg_sentence_indices, pos_neg_sentiment_label, sentiment_label)\n",
    "    asum_embedding.run(sentence_list_again, save_path=asum_embedding_path, print_iter=10, save_iter = 50, maxIters= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [01:18<05:15, 19.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start!! num_of_topic : 2, size : 100, window : 2, epoch : 5\n",
      "Starting iteration 10 of 100\n",
      "0.760142857143\n",
      "Starting iteration 20 of 100\n",
      "0.751428571429\n",
      "Starting save model\n",
      "Starting iteration 30 of 100\n",
      "0.749285714286\n",
      "Starting iteration 40 of 100\n",
      "0.747428571429\n",
      "Starting save model\n",
      "Starting iteration 50 of 100\n",
      "0.745285714286\n",
      "Starting iteration 60 of 100\n",
      "0.744571428571\n",
      "Starting save model\n",
      "Starting iteration 70 of 100\n",
      "0.743428571429\n",
      "Starting iteration 80 of 100\n",
      "0.741571428571\n",
      "Starting save model\n",
      "Starting iteration 90 of 100\n",
      "0.743571428571\n",
      "Starting iteration 100 of 100\n",
      "0.741285714286\n",
      "Starting save model\n",
      "END!! time : -1201.4870917797089\n",
      "start!! num_of_topic : 5, size : 100, window : 2, epoch : 5\n",
      "Starting iteration 10 of 100\n",
      "0.755142857143\n",
      "Starting iteration 20 of 100\n",
      "0.748\n",
      "Starting save model\n",
      "Starting iteration 30 of 100\n",
      "0.743571428571\n",
      "Starting iteration 40 of 100\n",
      "0.740285714286\n",
      "Starting save model\n",
      "Starting iteration 50 of 100\n",
      "0.732714285714\n",
      "Starting iteration 60 of 100\n",
      "0.733142857143\n",
      "Starting save model\n",
      "Starting iteration 70 of 100\n",
      "0.726714285714\n",
      "Starting iteration 80 of 100\n",
      "0.722\n",
      "Starting save model\n",
      "Starting iteration 90 of 100\n",
      "0.720857142857\n",
      "Starting iteration 100 of 100\n",
      "0.72\n",
      "Starting save model\n",
      "END!! time : -1794.4150087833405\n",
      "start!! num_of_topic : 10, size : 100, window : 2, epoch : 5\n",
      "Starting iteration 10 of 100\n",
      "0.750428571429\n",
      "Starting iteration 20 of 100\n",
      "0.743428571429\n",
      "Starting save model\n",
      "Starting iteration 30 of 100\n",
      "0.737571428571\n",
      "Starting iteration 40 of 100\n",
      "0.736285714286\n",
      "Starting save model\n",
      "Starting iteration 50 of 100\n",
      "0.735571428571\n",
      "Starting iteration 60 of 100\n",
      "0.737\n",
      "Starting save model\n",
      "Starting iteration 70 of 100\n",
      "0.731142857143\n",
      "Starting iteration 80 of 100\n",
      "0.734\n",
      "Starting save model\n",
      "Starting iteration 90 of 100\n",
      "0.732\n",
      "Starting iteration 100 of 100\n",
      "0.726857142857\n",
      "Starting save model\n",
      "END!! time : -2859.7906200885773\n",
      "start!! num_of_topic : 20, size : 100, window : 2, epoch : 5\n",
      "Starting iteration 10 of 100\n",
      "0.738857142857\n",
      "Starting iteration 20 of 100\n",
      "0.724714285714\n",
      "Starting save model\n",
      "Starting iteration 30 of 100\n",
      "0.721571428571\n",
      "Starting iteration 40 of 100\n",
      "0.721714285714\n",
      "Starting save model\n",
      "Starting iteration 50 of 100\n",
      "0.716571428571\n",
      "Starting iteration 60 of 100\n",
      "0.714714285714\n",
      "Starting save model\n",
      "Starting iteration 70 of 100\n",
      "0.711571428571\n",
      "Starting iteration 80 of 100\n",
      "0.714142857143\n",
      "Starting save model\n",
      "Starting iteration 90 of 100\n",
      "0.712428571429\n",
      "Starting iteration 100 of 100\n",
      "0.708714285714\n",
      "Starting save model\n",
      "END!! time : -4902.647294282913\n",
      "start!! num_of_topic : 50, size : 100, window : 2, epoch : 5\n",
      "Starting iteration 10 of 100\n",
      "0.739714285714\n",
      "Starting iteration 20 of 100\n",
      "0.735428571429\n",
      "Starting save model\n",
      "Starting iteration 30 of 100\n",
      "0.738714285714\n",
      "Starting iteration 40 of 100\n",
      "0.733571428571\n",
      "Starting save model\n",
      "Starting iteration 50 of 100\n",
      "0.730714285714\n",
      "Starting iteration 60 of 100\n",
      "0.729285714286\n",
      "Starting save model\n",
      "Starting iteration 70 of 100\n",
      "0.722857142857\n",
      "Starting iteration 80 of 100\n",
      "0.723142857143\n",
      "Starting save model\n",
      "Starting iteration 90 of 100\n",
      "0.723428571429\n",
      "Starting iteration 100 of 100\n",
      "0.719714285714\n",
      "Starting save model\n",
      "END!! time : -10845.364221811295\n",
      "start!! num_of_topic : 100, size : 100, window : 2, epoch : 5\n",
      "Starting iteration 10 of 100\n",
      "0.723142857143\n",
      "Starting iteration 20 of 100\n",
      "0.711714285714\n",
      "Starting save model\n",
      "Starting iteration 30 of 100\n",
      "0.702428571429\n",
      "Starting iteration 40 of 100\n",
      "0.697142857143\n",
      "Starting save model\n",
      "Starting iteration 50 of 100\n",
      "0.694857142857\n",
      "Starting iteration 60 of 100\n",
      "0.696714285714\n",
      "Starting save model\n",
      "Starting iteration 70 of 100\n",
      "0.694285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-5c74837375e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'#parmeter search\\nmodel_path = \"E:/dataset/MasterThesis/gensim_models/\"\\nasum_embedding_path = \"E:/dataset/MasterThesis/Models/ASUM_embedding\"\\n\\nwindow = [2,3,4,5]\\nsize = [100,200,300]\\nnum_topics = [2,5,10,20,50,100]\\npasses = 20\\nfor w in window:\\n    for s in size:\\n        model = Doc2Vec(dm=1, dm_mean=1, negative =10,min_count=0, sample=1e-5,\\n                        window=w, size=s, \\n                        workers=multiprocessing.cpu_count(), \\n                        alpha=0.025, min_alpha=0.025)\\n        model.build_vocab(documents)\\n\\n        for epoch in tqdm(range(passes)):\\n            random.shuffle(documents)\\n            model.train(documents)\\n            model.alpha -= 0.002  # decrease the learning rate\\n            model.min_alpha = model.alpha  # fix the learning rate, no decay\\n            if (epoch + 1) % 5 ==0:\\n                model.save(model_path + \\'model_\\' + str(w) + \\'_\\' + str(s) + \\'_\\' + str(epoch+1))\\n                \\n                # asum embedding model\\n                wordVectors = np.zeros((len(model.index2word), model.vector_size))\\n                for index, word in enumerate(model.index2word):\\n                    wordVectors[index,:] = model[word]\\n\\n                sentimentVector = np.zeros((2, model.vector_size))\\n                sentimentVector[0,:] = model.docvecs[\\'positive\\']\\n                sentimentVector[1,:] = model.docvecs[\\'negative\\']\\n                for k in num_topics:\\n                    print(\"start!! num_of_topic : %s, size : %s, window : %s, epoch : %s\"%(k,s,w,epoch+1))\\n                    start = time.time()\\n                    asum_embedding = ASUM_Embedding(wordVectors, sentimentVector, numTopics=k, alpha=0.01, beta=0.001, gamma=1, numSentiments=2)\\n                    asum_embedding._initialize_(sentence_list_again, pos_neg_sentence_indices, pos_neg_sentiment_label, sentiment_label)\\n                    asum_embedding.run(sentence_list_again, save_path=asum_embedding_path, print_iter=10, save_iter = 20, maxIters= 100)\\n                    end = time.time()\\n                    print(\"END!! time :\", start-end)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mD:\\Dropbox\\2016-2\\졸업논문\\STMD\\ASUM_Embedding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, reviews, save_path, print_iter, save_iter, maxIters)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumDocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumSentence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Dropbox\\2016-2\\졸업논문\\STMD\\ASUM_Embedding.py\u001b[0m in \u001b[0;36msampling\u001b[0;34m(self, d, m)\u001b[0m\n\u001b[1;32m    152\u001b[0m         topic_similarity = ot.softmax(np.dot(self.topicVectors,\n\u001b[1;32m    153\u001b[0m                                              self.wordVectors[\n\u001b[0;32m--> 154\u001b[0;31m                                                  self.doc_sent_word_dict[d][m]].T))  # ( K x num words in sentence)\n\u001b[0m\u001b[1;32m    155\u001b[0m         senti_similarity = ot.softmax(np.dot(self.sentimentVector,\n\u001b[1;32m    156\u001b[0m                                              self.wordVectors[\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#parmeter search\n",
    "model_path = \"E:/dataset/MasterThesis/gensim_models/\"\n",
    "asum_embedding_path = \"E:/dataset/MasterThesis/Models/ASUM_embedding\"\n",
    "\n",
    "window = [2,3,4,5]\n",
    "size = [100,200,300]\n",
    "num_topics = [2,5,10,20,50,100]\n",
    "passes = 20\n",
    "for w in window:\n",
    "    for s in size:\n",
    "        model = Doc2Vec(dm=1, dm_mean=1, negative =10,min_count=0, sample=1e-5,\n",
    "                        window=w, size=s, \n",
    "                        workers=multiprocessing.cpu_count(), \n",
    "                        alpha=0.025, min_alpha=0.025)\n",
    "        model.build_vocab(documents)\n",
    "\n",
    "        for epoch in tqdm(range(passes)):\n",
    "            random.shuffle(documents)\n",
    "            model.train(documents)\n",
    "            model.alpha -= 0.002  # decrease the learning rate\n",
    "            model.min_alpha = model.alpha  # fix the learning rate, no decay\n",
    "            if (epoch + 1) % 5 ==0:\n",
    "                model.save(model_path + 'model_' + str(w) + '_' + str(s) + '_' + str(epoch+1))\n",
    "                \n",
    "                # asum embedding model\n",
    "                wordVectors = np.zeros((len(model.index2word), model.vector_size))\n",
    "                for index, word in enumerate(model.index2word):\n",
    "                    wordVectors[index,:] = model[word]\n",
    "\n",
    "                sentimentVector = np.zeros((2, model.vector_size))\n",
    "                sentimentVector[0,:] = model.docvecs['positive']\n",
    "                sentimentVector[1,:] = model.docvecs['negative']\n",
    "                for k in num_topics:\n",
    "                    print(\"start!! num_of_topic : %s, size : %s, window : %s, epoch : %s\"%(k,s,w,epoch+1))\n",
    "                    start = time.time()\n",
    "                    asum_embedding = ASUM_Embedding(wordVectors, sentimentVector, numTopics=k, alpha=0.01, beta=0.001, gamma=1, numSentiments=2)\n",
    "                    asum_embedding._initialize_(sentence_list_again, pos_neg_sentence_indices, pos_neg_sentiment_label, sentiment_label)\n",
    "                    asum_embedding.run(sentence_list_again, save_path=asum_embedding_path, print_iter=10, save_iter = 20, maxIters= 100)\n",
    "                    end = time.time()\n",
    "                    print(\"END!! time :\", start-end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 4/20 [01:19<05:14, 19.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start!! num_of_topic : 50, size : 100, window : 3, epoch : 5\n",
      "Starting iteration 10 of 100\n",
      "0.742428571429\n",
      "Starting iteration 20 of 100\n",
      "0.741857142857\n",
      "Starting save model\n",
      "Starting iteration 30 of 100\n",
      "0.744142857143\n",
      "Starting iteration 40 of 100\n",
      "0.738857142857\n",
      "Starting save model\n",
      "Starting iteration 50 of 100\n",
      "0.735\n",
      "Starting iteration 60 of 100\n",
      "0.728428571429\n",
      "Starting save model\n",
      "Starting iteration 70 of 100\n",
      "0.725714285714\n",
      "Starting iteration 80 of 100\n",
      "0.721142857143\n",
      "Starting save model\n",
      "Starting iteration 90 of 100\n",
      "0.720142857143\n",
      "Starting iteration 100 of 100\n",
      "0.715857142857\n",
      "Starting save model\n",
      "END!! time : -11032.702196121216\n",
      "start!! num_of_topic : 30, size : 100, window : 3, epoch : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-00a8f5338e94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'#parmeter search\\nmodel_path = \"E:/dataset/MasterThesis/gensim_models/\"\\nasum_embedding_path = \"E:/dataset/MasterThesis/Models/ASUM_embedding\"\\n\\nwindow = [3,4,5]\\nsize = [100,200,300]\\nnum_topics = [50,30,20,10,5,2]\\npasses = 20\\nfor w in window:\\n    for s in size:\\n        model = Doc2Vec(dm=1, dm_mean=1, negative =10,min_count=0, sample=1e-5,\\n                        window=w, size=s, \\n                        workers=multiprocessing.cpu_count(), \\n                        alpha=0.025, min_alpha=0.025)\\n        model.build_vocab(documents)\\n\\n        for epoch in tqdm(range(passes)):\\n            random.shuffle(documents)\\n            model.train(documents)\\n            model.alpha -= 0.002  # decrease the learning rate\\n            model.min_alpha = model.alpha  # fix the learning rate, no decay\\n            if (epoch + 1) % 5 ==0:\\n                model.save(model_path + \\'model_\\' + str(w) + \\'_\\' + str(s) + \\'_\\' + str(epoch+1))\\n                \\n                # asum embedding model\\n                wordVectors = np.zeros((len(model.index2word), model.vector_size))\\n                for index, word in enumerate(model.index2word):\\n                    wordVectors[index,:] = model[word]\\n\\n                sentimentVector = np.zeros((2, model.vector_size))\\n                sentimentVector[0,:] = model.docvecs[\\'positive\\']\\n                sentimentVector[1,:] = model.docvecs[\\'negative\\']\\n                for k in num_topics:\\n                    print(\"start!! num_of_topic : %s, size : %s, window : %s, epoch : %s\"%(k,s,w,epoch+1))\\n                    start = time.time()\\n                    asum_embedding = ASUM_Embedding(wordVectors, sentimentVector, numTopics=k, alpha=0.01, beta=0.001, gamma=1, numSentiments=2)\\n                    asum_embedding._initialize_(sentence_list_again, pos_neg_sentence_indices, pos_neg_sentiment_label, sentiment_label)\\n                    asum_embedding.run(sentence_list_again, save_path=asum_embedding_path, print_iter=10, save_iter = 20, maxIters= 100)\\n                    end = time.time()\\n                    print(\"END!! time :\", start-end)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mD:\\Dropbox\\2016-2\\졸업논문\\STMD\\ASUM_Embedding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, reviews, save_path, print_iter, save_iter, maxIters)\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumDocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumSentence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Dropbox\\2016-2\\졸업논문\\STMD\\ASUM_Embedding.py\u001b[0m in \u001b[0;36msampling\u001b[0;34m(self, d, m)\u001b[0m\n\u001b[1;32m    152\u001b[0m         topic_similarity = ot.softmax(np.dot(self.topicVectors,\n\u001b[1;32m    153\u001b[0m                                              self.wordVectors[\n\u001b[0;32m--> 154\u001b[0;31m                                                  self.doc_sent_word_dict[d][m]].T))  # ( K x num words in sentence)\n\u001b[0m\u001b[1;32m    155\u001b[0m         senti_similarity = ot.softmax(np.dot(self.sentimentVector,\n\u001b[1;32m    156\u001b[0m                                              self.wordVectors[\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#parmeter search\n",
    "model_path = \"E:/dataset/MasterThesis/gensim_models/\"\n",
    "asum_embedding_path = \"E:/dataset/MasterThesis/Models/ASUM_embedding\"\n",
    "\n",
    "window = [3,4,5]\n",
    "size = [100,200,300]\n",
    "num_topics = [50,30,20,10,5,2]\n",
    "passes = 20\n",
    "for w in window:\n",
    "    for s in size:\n",
    "        model = Doc2Vec(dm=1, dm_mean=1, negative =10,min_count=0, sample=1e-5,\n",
    "                        window=w, size=s, \n",
    "                        workers=multiprocessing.cpu_count(), \n",
    "                        alpha=0.025, min_alpha=0.025)\n",
    "        model.build_vocab(documents)\n",
    "\n",
    "        for epoch in tqdm(range(passes)):\n",
    "            random.shuffle(documents)\n",
    "            model.train(documents)\n",
    "            model.alpha -= 0.002  # decrease the learning rate\n",
    "            model.min_alpha = model.alpha  # fix the learning rate, no decay\n",
    "            if (epoch + 1) % 5 ==0:\n",
    "                model.save(model_path + 'model_' + str(w) + '_' + str(s) + '_' + str(epoch+1))\n",
    "                \n",
    "                # asum embedding model\n",
    "                wordVectors = np.zeros((len(model.index2word), model.vector_size))\n",
    "                for index, word in enumerate(model.index2word):\n",
    "                    wordVectors[index,:] = model[word]\n",
    "\n",
    "                sentimentVector = np.zeros((2, model.vector_size))\n",
    "                sentimentVector[0,:] = model.docvecs['positive']\n",
    "                sentimentVector[1,:] = model.docvecs['negative']\n",
    "                for k in num_topics:\n",
    "                    print(\"start!! num_of_topic : %s, size : %s, window : %s, epoch : %s\"%(k,s,w,epoch+1))\n",
    "                    start = time.time()\n",
    "                    asum_embedding = ASUM_Embedding(wordVectors, sentimentVector, numTopics=k, alpha=0.01, beta=0.001, gamma=1, numSentiments=2)\n",
    "                    asum_embedding._initialize_(sentence_list_again, pos_neg_sentence_indices, pos_neg_sentiment_label, sentiment_label)\n",
    "                    asum_embedding.run(sentence_list_again, save_path=asum_embedding_path, print_iter=10, save_iter = 20, maxIters= 100)\n",
    "                    end = time.time()\n",
    "                    print(\"END!! time :\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic10</th>\n",
       "      <th>Topic11</th>\n",
       "      <th>Topic12</th>\n",
       "      <th>Topic13</th>\n",
       "      <th>Topic14</th>\n",
       "      <th>Topic15</th>\n",
       "      <th>Topic16</th>\n",
       "      <th>Topic17</th>\n",
       "      <th>Topic18</th>\n",
       "      <th>...</th>\n",
       "      <th>Topic28</th>\n",
       "      <th>Topic29</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic30</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Topic8</th>\n",
       "      <th>Topic9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>camera</td>\n",
       "      <td>camera</td>\n",
       "      <td>tv</td>\n",
       "      <td>camera</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>tv</td>\n",
       "      <td>use</td>\n",
       "      <td>camera</td>\n",
       "      <td>camera</td>\n",
       "      <td>...</td>\n",
       "      <td>one</td>\n",
       "      <td>batteri</td>\n",
       "      <td>camera</td>\n",
       "      <td>use</td>\n",
       "      <td>camera</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>use</td>\n",
       "      <td>len</td>\n",
       "      <td>set</td>\n",
       "      <td>great</td>\n",
       "      <td>samsung</td>\n",
       "      <td>work</td>\n",
       "      <td>samsung</td>\n",
       "      <td>samsung</td>\n",
       "      <td>bought</td>\n",
       "      <td>one</td>\n",
       "      <td>...</td>\n",
       "      <td>samsung</td>\n",
       "      <td>camera</td>\n",
       "      <td>use</td>\n",
       "      <td>camera</td>\n",
       "      <td>one</td>\n",
       "      <td>return</td>\n",
       "      <td>time</td>\n",
       "      <td>samsung</td>\n",
       "      <td>one</td>\n",
       "      <td>canon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>canon</td>\n",
       "      <td>one</td>\n",
       "      <td>one</td>\n",
       "      <td>one</td>\n",
       "      <td>one</td>\n",
       "      <td>one</td>\n",
       "      <td>use</td>\n",
       "      <td>...</td>\n",
       "      <td>appl</td>\n",
       "      <td>use</td>\n",
       "      <td>get</td>\n",
       "      <td>one</td>\n",
       "      <td>use</td>\n",
       "      <td>camera</td>\n",
       "      <td>get</td>\n",
       "      <td>problem</td>\n",
       "      <td>product</td>\n",
       "      <td>len</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>get</td>\n",
       "      <td>one</td>\n",
       "      <td>get</td>\n",
       "      <td>pictur</td>\n",
       "      <td>appl</td>\n",
       "      <td>time</td>\n",
       "      <td>use</td>\n",
       "      <td>tablet</td>\n",
       "      <td>use</td>\n",
       "      <td>purchas</td>\n",
       "      <td>...</td>\n",
       "      <td>get</td>\n",
       "      <td>tablet</td>\n",
       "      <td>tv</td>\n",
       "      <td>product</td>\n",
       "      <td>appl</td>\n",
       "      <td>one</td>\n",
       "      <td>hour</td>\n",
       "      <td>camera</td>\n",
       "      <td>would</td>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tablet</td>\n",
       "      <td>get</td>\n",
       "      <td>would</td>\n",
       "      <td>love</td>\n",
       "      <td>get</td>\n",
       "      <td>veri</td>\n",
       "      <td>would</td>\n",
       "      <td>return</td>\n",
       "      <td>screen</td>\n",
       "      <td>product</td>\n",
       "      <td>...</td>\n",
       "      <td>drive</td>\n",
       "      <td>charg</td>\n",
       "      <td>samsung</td>\n",
       "      <td>would</td>\n",
       "      <td>product</td>\n",
       "      <td>amazon</td>\n",
       "      <td>tri</td>\n",
       "      <td>updat</td>\n",
       "      <td>appl</td>\n",
       "      <td>samsung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>would</td>\n",
       "      <td>would</td>\n",
       "      <td>samsung</td>\n",
       "      <td>use</td>\n",
       "      <td>would</td>\n",
       "      <td>would</td>\n",
       "      <td>product</td>\n",
       "      <td>amazon</td>\n",
       "      <td>veri</td>\n",
       "      <td>get</td>\n",
       "      <td>...</td>\n",
       "      <td>use</td>\n",
       "      <td>video</td>\n",
       "      <td>one</td>\n",
       "      <td>like</td>\n",
       "      <td>get</td>\n",
       "      <td>work</td>\n",
       "      <td>batteri</td>\n",
       "      <td>issu</td>\n",
       "      <td>get</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>need</td>\n",
       "      <td>canon</td>\n",
       "      <td>pictur</td>\n",
       "      <td>bought</td>\n",
       "      <td>tv</td>\n",
       "      <td>tv</td>\n",
       "      <td>get</td>\n",
       "      <td>tv</td>\n",
       "      <td>great</td>\n",
       "      <td>would</td>\n",
       "      <td>...</td>\n",
       "      <td>would</td>\n",
       "      <td>gb</td>\n",
       "      <td>len</td>\n",
       "      <td>canon</td>\n",
       "      <td>buy</td>\n",
       "      <td>get</td>\n",
       "      <td>tablet</td>\n",
       "      <td>work</td>\n",
       "      <td>devic</td>\n",
       "      <td>get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>video</td>\n",
       "      <td>veri</td>\n",
       "      <td>screen</td>\n",
       "      <td>len</td>\n",
       "      <td>amazon</td>\n",
       "      <td>like</td>\n",
       "      <td>work</td>\n",
       "      <td>camera</td>\n",
       "      <td>new</td>\n",
       "      <td>samsung</td>\n",
       "      <td>...</td>\n",
       "      <td>tv</td>\n",
       "      <td>turn</td>\n",
       "      <td>take</td>\n",
       "      <td>thing</td>\n",
       "      <td>purchas</td>\n",
       "      <td>buy</td>\n",
       "      <td>would</td>\n",
       "      <td>tablet</td>\n",
       "      <td>like</td>\n",
       "      <td>repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>work</td>\n",
       "      <td>tv</td>\n",
       "      <td>turn</td>\n",
       "      <td>one</td>\n",
       "      <td>like</td>\n",
       "      <td>app</td>\n",
       "      <td>purchas</td>\n",
       "      <td>product</td>\n",
       "      <td>love</td>\n",
       "      <td>tv</td>\n",
       "      <td>...</td>\n",
       "      <td>amazon</td>\n",
       "      <td>flash</td>\n",
       "      <td>pictur</td>\n",
       "      <td>veri</td>\n",
       "      <td>bought</td>\n",
       "      <td>love</td>\n",
       "      <td>one</td>\n",
       "      <td>one</td>\n",
       "      <td>tablet</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>also</td>\n",
       "      <td>time</td>\n",
       "      <td>sound</td>\n",
       "      <td>return</td>\n",
       "      <td>work</td>\n",
       "      <td>problem</td>\n",
       "      <td>set</td>\n",
       "      <td>would</td>\n",
       "      <td>ipad</td>\n",
       "      <td>new</td>\n",
       "      <td>...</td>\n",
       "      <td>new</td>\n",
       "      <td>ppi</td>\n",
       "      <td>would</td>\n",
       "      <td>work</td>\n",
       "      <td>canon</td>\n",
       "      <td>canon</td>\n",
       "      <td>work</td>\n",
       "      <td>app</td>\n",
       "      <td>comput</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic1 Topic10  Topic11 Topic12  Topic13  Topic14  Topic15  Topic16  \\\n",
       "0  camera  camera       tv  camera      use      use       tv      use   \n",
       "1     use     len      set   great  samsung     work  samsung  samsung   \n",
       "2     one     use      use   canon      one      one      one      one   \n",
       "3     get     one      get  pictur     appl     time      use   tablet   \n",
       "4  tablet     get    would    love      get     veri    would   return   \n",
       "5   would   would  samsung     use    would    would  product   amazon   \n",
       "6    need   canon   pictur  bought       tv       tv      get       tv   \n",
       "7   video    veri   screen     len   amazon     like     work   camera   \n",
       "8    work      tv     turn     one     like      app  purchas  product   \n",
       "9    also    time    sound  return     work  problem      set    would   \n",
       "\n",
       "  Topic17  Topic18   ...     Topic28  Topic29   Topic3  Topic30   Topic4  \\\n",
       "0  camera   camera   ...         one  batteri   camera      use   camera   \n",
       "1  bought      one   ...     samsung   camera      use   camera      one   \n",
       "2     one      use   ...        appl      use      get      one      use   \n",
       "3     use  purchas   ...         get   tablet       tv  product     appl   \n",
       "4  screen  product   ...       drive    charg  samsung    would  product   \n",
       "5    veri      get   ...         use    video      one     like      get   \n",
       "6   great    would   ...       would       gb      len    canon      buy   \n",
       "7     new  samsung   ...          tv     turn     take    thing  purchas   \n",
       "8    love       tv   ...      amazon    flash   pictur     veri   bought   \n",
       "9    ipad      new   ...         new      ppi    would     work    canon   \n",
       "\n",
       "   Topic5   Topic6   Topic7   Topic8   Topic9  \n",
       "0     use      use      use      use   camera  \n",
       "1  return     time  samsung      one    canon  \n",
       "2  camera      get  problem  product      len  \n",
       "3     one     hour   camera    would    would  \n",
       "4  amazon      tri    updat     appl  samsung  \n",
       "5    work  batteri     issu      get      one  \n",
       "6     get   tablet     work    devic      get  \n",
       "7     buy    would   tablet     like   repair  \n",
       "8    love      one      one   tablet      use  \n",
       "9   canon     work      app   comput   amazon  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asum_embedding.getTopKWordsByTopic(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.6234"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents) / 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
